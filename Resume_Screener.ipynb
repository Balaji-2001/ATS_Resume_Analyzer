{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9aa30787",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from langchain_community.document_loaders import PyPDFLoader, TextLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import FAISS, Chroma\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fc8e810f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ CELL 2: Data Loader Ready!\n"
     ]
    }
   ],
   "source": [
    "# Sep 1: DATA LOADING\n",
    "\n",
    "class DataLoader:\n",
    "    def load_job_description(self, job_text):\n",
    "        return [Document(page_content=job_text)]\n",
    "    \n",
    "    def load_resume(self, file):\n",
    "        if file.name.endswith('.pdf'):\n",
    "            loader = PyPDFLoader(file)\n",
    "        else:\n",
    "            loader = TextLoader(file.name)\n",
    "        return loader.load()\n",
    "\n",
    "# Test\n",
    "loader = DataLoader()\n",
    "print(\"‚úÖ CELL 2: Data Loader Ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8eff3b68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ CELL 3: Text Chunker Ready!\n"
     ]
    }
   ],
   "source": [
    "# *CELL 3: TEXT CHUNKING\n",
    "\n",
    "\n",
    "class TextChunker:\n",
    "    def __init__(self):\n",
    "        self.splitter = RecursiveCharacterTextSplitter(\n",
    "            chunk_size=300, chunk_overlap=50  # Resume optimized\n",
    "        )\n",
    "    \n",
    "    def chunk_documents(self, docs):\n",
    "        return self.splitter.split_documents(docs)\n",
    "\n",
    "# Test  \n",
    "chunker = TextChunker()\n",
    "print(\"‚úÖ CELL 3: Text Chunker Ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b14f86f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ CELL 4: Embeddings Ready!\n"
     ]
    }
   ],
   "source": [
    "## *CELL 4: EMBEDDING MANAGER \n",
    "\n",
    "class EmbeddingManager:\n",
    "    def __init__(self):\n",
    "        self.embeddings = HuggingFaceEmbeddings(\n",
    "            model_name=\"sentence-transformers/all-MiniLM-L6-v2\"  # FREE!\n",
    "        )\n",
    "    \n",
    "    def get_embeddings(self):\n",
    "        return self.embeddings\n",
    "\n",
    "# Test\n",
    "embedder = EmbeddingManager()\n",
    "print(\"‚úÖ CELL 4: Embeddings Ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c345a176",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ CELL 5: Vector Store Ready!\n"
     ]
    }
   ],
   "source": [
    "# *CELL 5: VECTOR STORE (FAISS)\n",
    "\n",
    "class VectorStore:\n",
    "    def __init__(self):\n",
    "        self.embedding_manager = EmbeddingManager()\n",
    "        self.job_store = None\n",
    "    \n",
    "    def create_vectorstore(self, chunks):\n",
    "        return FAISS.from_documents(chunks, self.embedding_manager.get_embeddings())\n",
    "    \n",
    "    def similarity_search(self, vectorstore, query, k=5):\n",
    "        return vectorstore.similarity_search(query, k=k)\n",
    "\n",
    "# Test\n",
    "vector_store = VectorStore()\n",
    "print(\"‚úÖ CELL 5: Vector Store Ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9364e6b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ CELL 6: Prompt + Retriever Ready!\n"
     ]
    }
   ],
   "source": [
    "## *CELL 6: PROMPT + CONTEXT RETRIEVAL\n",
    "\n",
    "class PromptRetriever:\n",
    "    def get_context(self, vectorstore, query=\"skills experience python ml langchain\"):\n",
    "        matches = vectorstore.similarity_search(query, k=5)\n",
    "        return \"\\n\".join([doc.page_content for doc in matches])\n",
    "    \n",
    "    def get_prompt(self, job_desc, context):\n",
    "        return f\"\"\"\n",
    "AI RESUME SCREENER (Krish Naik RAG)\n",
    "\n",
    "JOB REQUIREMENTS:\n",
    "{job_desc}\n",
    "\n",
    "RESUME MATCHES:\n",
    "{context}\n",
    "\n",
    "Score 0-100:\n",
    "Skills: 40pts | Experience: 30pts | Projects: 20pts | Education: 10pts\n",
    "\n",
    "**FORMAT:**\n",
    "**SCORE:** XX/100\n",
    "**VERDICT:** Hire/Maybe/Reject\n",
    "**STRENGTHS:** [3 bullets]\n",
    "**GAPS:** [3 bullets]\n",
    "\"\"\"\n",
    "\n",
    "# Test\n",
    "retriever = PromptRetriever()\n",
    "print(\"‚úÖ CELL 6: Prompt + Retriever Ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "da26a0ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ CELL 7: LLM Generator Ready!\n"
     ]
    }
   ],
   "source": [
    "## *CELL 7: LLM GENERATOR\n",
    "\n",
    "class LLMGenerator:\n",
    "    def generate(self, prompt):\n",
    "        response = ollama.chat(model='mistral:7b', messages=[\n",
    "            {'role': 'user', 'content': prompt}\n",
    "        ])\n",
    "        return response['message']['content']\n",
    "\n",
    "# Test\n",
    "generator = LLMGenerator()\n",
    "print(\"‚úÖ CELL 7: LLM Generator Ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "64bbc430",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ CELL 8: RAG Pipeline Complete!\n"
     ]
    }
   ],
   "source": [
    "## *CELL 8: COMPLETE RAG PIPELINE\n",
    "\n",
    "class ResumeRAGPipeline:\n",
    "    def __init__(self):\n",
    "        self.loader = DataLoader()\n",
    "        self.chunker = TextChunker()\n",
    "        self.vector_store = VectorStore()\n",
    "        self.retriever = PromptRetriever()\n",
    "        self.generator = LLMGenerator()\n",
    "        st.success(\"üöÄ COMPLETE 8-STEP RAG PIPELINE READY!\")\n",
    "    \n",
    "    def run_pipeline(self, job_desc, resume_file):\n",
    "        # STEP 1: Load Data\n",
    "        st.info(\"üì• 1. LOADING DATA...\")\n",
    "        job_docs = self.loader.load_job_description(job_desc)\n",
    "        resume_docs = self.loader.load_resume(resume_file)\n",
    "        \n",
    "        # STEP 2: Chunk\n",
    "        st.info(\"‚úÇÔ∏è 2. CHUNKING...\")\n",
    "        job_chunks = self.chunker.chunk_documents(job_docs)\n",
    "        resume_chunks = self.chunker.chunk_documents(resume_docs)\n",
    "        \n",
    "        # STEP 3-4: Embeddings + Vector Store  \n",
    "        st.info(\"üî¢ 3-4. EMBEDDING + VECTOR STORE...\")\n",
    "        job_vectorstore = self.vector_store.create_vectorstore(job_chunks)\n",
    "        \n",
    "        # STEP 5-6: Retrieve Context\n",
    "        st.info(\"üîç 5-6. RETRIEVING CONTEXT...\")\n",
    "        context = self.retriever.get_context(job_vectorstore)\n",
    "        prompt = self.retriever.get_prompt(job_desc, context)\n",
    "        \n",
    "        # STEP 7: Generate\n",
    "        st.info(\"ü§ñ 7-8. AI GENERATION...\")\n",
    "        result = self.generator.generate(prompt)\n",
    "        \n",
    "        return result\n",
    "\n",
    "print(\"‚úÖ CELL 8: RAG Pipeline Complete!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AI_Resume_Screener",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
